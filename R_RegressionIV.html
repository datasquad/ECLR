<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>R, Instrumental Variables Estimations</title>

<script src="site_libs/header-attrs-2.21/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/yeti.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">HOME</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="examples.html">Examples</a>
</li>
<li>
  <a href="Datasets.html">Datasets</a>
</li>
<li>
  <a href="resources.html">Resources</a>
</li>
<li>
  <a href="Author.html">Author</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">R, Instrumental Variables Estimations</h1>

</div>


<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>In this Section we will demonstrate how to use instrumental variables
(IV) estimation (or better Two-Stage-Least Squares, 2SLS) to estimate
the parameters in a linear regression model. If you want some more
theoretical background on why we may need to use these techniques you
may want to refer to any decent Econometrics textbook.</p>
<p>Here we will be very short on the problem setup and big on the
implementation! When you estimate a linear regression model, say</p>
<p><span class="math inline">\(y = \alpha_0 + \alpha_1 x_1 + \alpha_2
x_2 + \alpha_3 x_3 + u\)</span></p>
<p>the most crucial of all assumptions you got to make is that the
explanatory variables <span class="math inline">\(x_1\)</span> to <span
class="math inline">\(x_3\)</span> are uncorrelated to the error term
<span class="math inline">\(u\)</span>. Of course, the error term <span
class="math inline">\(u\)</span> is unobservable and hence it is
impossible to empirically test this assumption (notwithstanding a
related test introduced below) and you ought to think very carefully
whether there may be any reason that makes it likely that this
assumption might be breached. Seasoned econometricians would immediately
rattle down simultaneity bias, measurement error and omitted relevant
variables as the three causes for this to happen.</p>
<p>In some such situations you can actually fix the problem, e.g.Â by
including additional explanatory variables into the model, but in others
that is impossible and you need to accept that there is a high
probability that, say, <span class="math inline">\(x_3\)</span> is
correlated with <span class="math inline">\(u\)</span>. We would then
call <span class="math inline">\(x_3\)</span> an endogenous variable and
all those explanatory variables that do not have that issue are called
exogenous. If you still persist with estimating that model by Ordinary
Least Squares (OLS) you will have to accept that your estimated
coefficients come from a random distribution that on average will not
produce the correct (yet unknown) value, in technical lingo, the
estimators are biased.</p>
<p>To the rescue come instrumental variables (IV) estimation. What we
need to use this technique is what is called an instrumental variable.
And if only <span class="math inline">\(x_3\)</span> is potentially
correlated with the error term we need at least one such variable, but
more could be useful as well. You always need at least as many
instruments as you have endogenous variables. These instruments need to
have the following crucial properties, they need to be correlated to the
endogenous variable, uncorrelated to the error term and shouldnât be
part of the model explaining the dependent variable <span
class="math inline">\(y\)</span>.</p>
</div>
<div id="the-basic-idea-of-iv2sls" class="section level1">
<h1>The basic idea of IV/2SLS</h1>
<p>Here is a brief outline of what happens when you use IV, in the form
of a TSLS regression.</p>
<ol style="list-style-type: decimal">
<li>Take all of your endogenous variables and run regressions with these
as the dependent variable and all other exogenous and all instrumental
variables as explanatory variables. From these regressions you get the
predicted values for all your endogenous variables, e.g.Â <span
class="math inline">\(\hat{x}_3\)</span>. These regression(s) are called
first stage regressions. The idea is that, as all explanatory variables
in this first stage regression are assumed to be uncorrelated with the
error term, the variable <span class="math inline">\(\hat{x}_3\)</span>
is also uncorrelated with the unobserved error term <span
class="math inline">\(u\)</span>. All variation in <span
class="math inline">\(x_3\)</span> that was correlated with the error
term <span class="math inline">\(u\)</span> must have ended up in the
error term of this auxilliary regression.</li>
<li>In the second stage of the procedure we return to our original
regression model and replace <span class="math inline">\(x_3\)</span>
with <span class="math inline">\(\hat{x}_3\)</span> and then estimate
values for the parameters <span class="math inline">\(\alpha_0\)</span>
to <span class="math inline">\(\alpha_3\)</span> by OLS. These
estimators, at least for sufficiently large samples and sufficiently
large correlation of the instruments with endogenous variables, will
deliver unbiased estimates (technical lingo: consistent).</li>
</ol>
<p>This sounds pretty easy. There is a slight complication, the standard
errors that the second stage OLS regression delivers are incorrect and
we need to calculate different standard errors. But that will happen
automatically in the procedure below.</p>
</div>
<div id="implementation-in-r" class="section level1">
<h1>Implementation in R</h1>
<p>The R Package needed is the AER package which is a package also
recommended for use in the context of estimating robust standard errors.
Included in that package is a function called ivreg which we will use.
We explain how to use it by walking through an example.</p>
<p>If you use IV a lot in your work, you may well want to pack all of
the following into one convenient function (just as Alan Fernihough has
done <a
href="https://diffuseprior.wordpress.com/2012/05/03/an-ivreg2-function-for-r/">here</a>.
But if you are applying IV for the first time it is actually very
instructive to go through some of the steps in a bit more detail. It is
is also good to see that really there is not a lot of technical magic â¦
just a great idea!</p>
<pre class="r"><code>library(tidyverse)  #  for general data handling
library(stargazer)  # package for nicer regression output
library(AER)        # include the ARE package</code></pre>
<div id="example" class="section level2">
<h2>Example</h2>
<p>We will use the Womenâs Wages dataset to illustrate the use of the IV
regression (<a
href="https://github.com/datasquad/ECLR/blob/gh-pages/data/Mroz.csv">mroz.csv</a>).
The dependent variable which we use here is the log wage
<code>lwage</code> and we are interested in whether the years of
education (<code>educ</code>) has a positive influence on this log wage
(here we mirror the analysis in Wooldridgeâs Example 15.1 in his
Introductory Econometrics textbook).</p>
<p>Letâs first import the data</p>
<pre class="r"><code>setwd(&quot;YOUR/DIRECTORY/PATH&quot;)              # This sets the working directory
mydata &lt;- read.csv(&quot;mroz.csv&quot;, na.strings = &quot;.&quot;)  # Opens mroz.csv from working directory</code></pre>
<p>And also letâs remove all observations with missing wages from the
dataframe</p>
<pre class="r"><code>mydata &lt;- subset(mydata, is.na(wage) == FALSE)   # remove observations with missing wages from dataset</code></pre>
<p>or if you wish to use the <code>tidyverse</code> methodology</p>
<pre class="r"><code>mydata &lt;- mydata %&gt;%  filter(!is.na(wage))</code></pre>
<p>An extremely simple model would be to estimate the following OLS
regression which models lwage as a function of a constant and educ.</p>
<pre class="r"><code>reg_ex0 &lt;- lm(lwage~educ,data=mydata)
stargazer(reg_ex0, type = &quot;text&quot;, title = &quot;OLS estimation&quot;)</code></pre>
<pre><code>## 
## OLS estimation
## ===============================================
##                         Dependent variable:    
##                     ---------------------------
##                                lwage           
## -----------------------------------------------
## educ                         0.110***          
##                               (0.014)          
##                                                
## Constant                      -0.180           
##                               (0.180)          
##                                                
## -----------------------------------------------
## Observations                    428            
## R2                             0.120           
## Adjusted R2                    0.120           
## Residual Std. Error      0.680 (df = 426)      
## F Statistic           57.000*** (df = 1; 426)  
## ===============================================
## Note:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<p>This seems to indicate that every additional year of education
increases the wage by almost 11% (recall the interpretation of a
coefficient in a log-lin model!). The issue with this sort of model is
that education is most likely to be correlated with individual
characteristics that are important for the personâs wage, but not
modeled (and hence captured by the error term).</p>
<p>What we need is an instrument that meets the conditions outlined
above and here and as in Wooldridgeâs example we use the fatherâs
education as an instrument. The way to do this is as follows:</p>
<pre class="r"><code>reg_iv0 &lt;- ivreg(lwage~educ|fatheduc,data=mydata)
stargazer(reg_iv0, type = &quot;text&quot;, title = &quot;IV estimation&quot;)</code></pre>
<pre><code>## 
## IV estimation
## ===============================================
##                         Dependent variable:    
##                     ---------------------------
##                                lwage           
## -----------------------------------------------
## educ                          0.059*           
##                               (0.035)          
##                                                
## Constant                       0.440           
##                               (0.450)          
##                                                
## -----------------------------------------------
## Observations                    428            
## R2                             0.093           
## Adjusted R2                    0.091           
## Residual Std. Error      0.690 (df = 426)      
## ===============================================
## Note:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<p>The <code>ivreg</code> function works very similar to the
<code>lm</code> function (as usual use <code>?ivreg</code> to get more
detailed help). In fact the only difference is the specification of the
instrument <code>|fatheduc</code>. The instruments follow the model
specification. Behind the vertical lines we find the instrument used to
instrument the educ variable (The order of the variables after the
vertical line doesnât matter).</p>
<p>Clearly, the effect of an additional year of education, has
significantly dropped and is now only marginally significant. It is, of
course, often a feature of IV estimation that the estimated standard
errors are significantly larger than those of the OLS estimators. The
size of the standard error depends a lot on the strength of the relation
between the endogenous explanatory variables which we can be checked by
looking at the Rsquared of the regression of educ on fatheduc (Which
turns out to be 0.1958 if you check it.).</p>
<p>In order to illustrate the full functionality of the ivreg procedure
we re-estimate the model with extra explanatory variables and more
instruments than endogenous variables which means that really we are
applying a 2SLS estimation (This is the example estimated in
Wooldridgeâs Example 15.5). Letâs start by estimating this model by OLS
(as we need this result later, but result not shown here).</p>
<pre class="r"><code>reg_1 &lt;- lm(lwage~educ+age+exper+expersq, data=mydata) # OLS estimation
stargazer(reg_1, type = &quot;text&quot;, title = &quot;OLS estimation&quot;)</code></pre>
<pre><code>## 
## OLS estimation
## ===============================================
##                         Dependent variable:    
##                     ---------------------------
##                                lwage           
## -----------------------------------------------
## educ                         0.110***          
##                               (0.014)          
##                                                
## age                           0.0003           
##                               (0.005)          
##                                                
## exper                        0.042***          
##                               (0.013)          
##                                                
## expersq                      -0.001**          
##                              (0.0004)          
##                                                
## Constant                      -0.530*          
##                               (0.280)          
##                                                
## -----------------------------------------------
## Observations                    428            
## R2                             0.160           
## Adjusted R2                    0.150           
## Residual Std. Error      0.670 (df = 423)      
## F Statistic           20.000*** (df = 4; 423)  
## ===============================================
## Note:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<p>The estimated coefficient for educ is 0.108 with standard error 0.014
(the rest of the results are not shown). Then we estimate the TSLS
regression with <code>fatheduc</code> and <code>matheduc</code> as
instruments.</p>
<pre class="r"><code>reg_iv1 &lt;- ivreg(lwage~educ+age+exper+expersq|fatheduc+motheduc+age+exper+expersq,data=mydata)
stargazer(reg_1, reg_iv1, type = &quot;text&quot;, title = &quot;OLS and IV estimation&quot;)</code></pre>
<pre><code>## 
## OLS and IV estimation
## ===================================================================
##                                        Dependent variable:         
##                                ------------------------------------
##                                               lwage                
##                                          OLS           instrumental
##                                                          variable  
##                                          (1)               (2)     
## -------------------------------------------------------------------
## educ                                  0.110***            0.061*   
##                                        (0.014)           (0.032)   
##                                                                    
## age                                    0.0003            -0.0004   
##                                        (0.005)           (0.005)   
##                                                                    
## exper                                 0.042***           0.044***  
##                                        (0.013)           (0.013)   
##                                                                    
## expersq                               -0.001**           -0.001**  
##                                       (0.0004)           (0.0004)  
##                                                                    
## Constant                               -0.530*            0.067    
##                                        (0.280)           (0.460)   
##                                                                    
## -------------------------------------------------------------------
## Observations                             428               428     
## R2                                      0.160             0.140    
## Adjusted R2                             0.150             0.130    
## Residual Std. Error (df = 423)          0.670             0.680    
## F Statistic                    20.000*** (df = 4; 423)             
## ===================================================================
## Note:                                   *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<p>Before the vertical line we can see the model that is to be
estimeted, <code>lwage~educ+age+exper+expersq</code>. All the action is
after the vertical line. First we see the instrumental variables used to
instrument educ, <code>fatheduc+motheduc</code>; this is followed by all
the explanatory variables that are considered exogenous,
<code>age+exper+expersq</code>.</p>
<p>When you have a model with a lot of variables this way of calling an
IV estimation can be quite unwieldy as you have to replicate all the
exogenous variables. A slightly different, more economical way of asking
R to do the same thing is as follows</p>
<pre class="r"><code>reg_iv1b &lt;- ivreg(lwage~educ+age+exper+expersq|.-educ+fatheduc+motheduc,data=mydata)</code></pre>
<p>After the vertical line you are basically telling R which variable to
remove from the instrument set (the endogenous variable,
<code>.-educ</code>) and which to add (<code>+fatheduc+motheduc</code>).
Make sure you donât forget the decimal point straight after the vertical
line when you use this way of specifying the instruments. The results in
<code>reg_iv1</code> and <code>reg_ivb</code> are identical.</p>
</div>
</div>
<div id="iv-related-testing-procedures" class="section level1">
<h1>IV related Testing procedures</h1>
<p>One feature of IV estimations is that in general it is an inferior
estimator of <span class="math inline">\(\beta\)</span> if all
explanatory variables are exogenous. In that case, assuming that all
other Gauss-Markov assumptions are met, the OLS estimator is the BLUE
estimator. In other words, IV estimators have larger standard errors for
the coefficient estimates. Therefore, one would really like to avoid
having to rely on IV estimators, unless, of course, they are the only
estimators that deliver consistent estimates.</p>
<p>So there are usually three tests one performs in this context.
Firstly a test to examine that the chosen instruments are indeed
sufficiently strong correlated to the endogenous variable (Instrument
relevance); whether the potentially endogenous variable is indeed
endogenous (Testing for exogeneity) and finally that the instruments are
indeed exogenous.</p>
<div id="instrument-relevance" class="section level2">
<h2>Instrument relevance</h2>
<p>The entire 2SLS procedure hinges on the instruments chosen being
useful instruments. Useful here means that they are sufficiently
strongly correlated to the endogenous variable.</p>
<p>We can use the first stage regression (described in the Introduction)
to test whether that is indeed the case. So here is the first stage
regression:</p>
<pre class="r"><code># First Stage
reg_fs1 &lt;- lm(educ~age+exper+expersq+fatheduc+motheduc,data=mydata)</code></pre>
<p>What we now need to know is whether the instruments
<code>fatheduc</code> and <code>motheduc</code> explain a sufficient
amount of variation in <code>educ</code>. We can use a standard F-test
to test this. Here is the easiest way to implement this using the
<code>lht</code> (short for linear hypothesis testing) function. We are
basically testing the null hypothesis that the coefficients to
<code>fatheduc</code> and <code>motheduc</code> are equal to 0.</p>
<pre class="r"><code>lht(reg_fs1, c(&quot;fatheduc = 0&quot;,&quot; motheduc = 0&quot;))</code></pre>
<pre><code>## Linear hypothesis test
## 
## Hypothesis:
## fatheduc = 0
## motheduc = 0
## 
## Model 1: restricted model
## Model 2: educ ~ age + exper + expersq + fatheduc + motheduc
## 
##   Res.Df  RSS Df Sum of Sq    F Pr(&gt;F)    
## 1    424 2216                             
## 2    422 1758  2       458 54.9 &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The value of the F_test is 54.943 with an extremely low p-value. So
in this case we can clearly reject the null hypothesis that the
instruments are irrelevant.</p>
</div>
<div id="testing-for-exogeneity" class="section level2">
<h2>Testing for exogeneity</h2>
<p>You really only want to use IV/TSLS if you are really dealing with
endogenous explanatory variables. If the variable you suspected wasnât
endogenous, then IV only has disadvantages compared to OLS. Most
crucially it will deliver much larger standard errors. For this reason
you really want to make sure that you do have an endogeneity
problem.</p>
<p>The celebrated test to use in this case is the Hausman test. Here we
use a slightly different implementation to the original Hausman test,
the so-called Hausman-Wu test.</p>
<p>In the end it is pretty straighforward and you only need simple
regressions to implement it. In a first step you run the first step
regression(s) of the TSLS procedure, which we did earlier and saved the
results in <code>reg_fs1</code>. In a second step you add the
residual(s) from this first step into the original model:</p>
<pre class="r"><code>reg_HSW1 &lt;- lm(lwage~educ+age+exper+expersq+reg_fs1$residuals,data=mydata)</code></pre>
<p>Now we need to compare this result to the one we got from the
original model reg_2. If the educ is indeed endogenous, then the first
stage regression should have isolated the variation of <code>educ</code>
that was correlated with error term in the residual of the first stage
regression. In that case the included <code>reg_fs1$residuals</code>
should be relevant. As there may potentially be more than one endogenous
variable and hence more than one first stage residual we use an F-test
to test the null hypothesis that these residuals are irrelevant (and
hence endogeneity not being a problem).</p>
<pre class="r"><code>lht(reg_HSW1, c(&quot;reg_fs1$residuals = 0&quot;))</code></pre>
<pre><code>## Linear hypothesis test
## 
## Hypothesis:
## reg_fs1$residuals = 0
## 
## Model 1: restricted model
## Model 2: lwage ~ educ + age + exper + expersq + reg_fs1$residuals
## 
##   Res.Df RSS Df Sum of Sq    F Pr(&gt;F)  
## 1    423 188                           
## 2    422 187  1      1.25 2.82  0.094 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The result is a p-value of 0.094. So at an <span
class="math inline">\(\alpha = 0.05\)</span> we just fail to reject the
null of <span class="math inline">\(educ\)</span> being exogenous,
however, at an <span class="math inline">\(\alpha = 0.10\)</span> we
would reject endogeneity of <code>educ</code>. So the case for using IV
or OLS is not clearcut here.</p>
<div id="sargan-test-for-instrument-validity" class="section level3">
<h3>Sargan test for instrument validity</h3>
<p>One crucial property of instruments is that they ought to be
uncorrelated to the regression error terms <span
class="math inline">\(u\)</span>. Instrument exogeneity is set as the
null hypothesis of this following test with the alternative hypothesis
being that the instruments are endogenous. This test can only be applied
if you have more instruments than endogenous variables. It is therefore
sometimes also called the test for overidentifying restrictions.</p>
<p>The test is rather simple to implement. Take the residuals from the
2SLS regression <code>reg_iv1$residuals</code> and use them as the
dependent variable in a new regression in which you regress them on all
exogenous explanatory variables and all instruments.</p>
<pre class="r"><code>reg_sargan1 &lt;- lm(reg_iv1$residuals~age+exper+expersq+fatheduc+motheduc,data=mydata)
reg_sargan_sm &lt;- summary(reg_sargan1)</code></pre>
<p>If the instruments are valid (null hypothesis), they should be
uncorrelated to these residuals and hence we apply the following <span
class="math inline">\(\chi^2\)</span> test. We use the <span
class="math inline">\(R^2\)</span> of this regression and calculate
<span class="math inline">\(n*R^2\)</span>.</p>
<pre class="r"><code>Sargan_test &lt;- reg_sargan_sm$r.squared*nrow(mydata)
print(Sargan_test)</code></pre>
<pre><code>## [1] 0.4</code></pre>
<pre class="r"><code>print(1-pchisq(Sargan_test,1))  # prints p-value</code></pre>
<pre><code>## [1] 0.53</code></pre>
<p>We find that the p-value of this test is 0.5260 and hence we do not
reject the null hypothesis of instrument validity. The p-value was
obtained from a <span class="math inline">\(\chi^2\)</span> distribution
with one degree of freedom. That was one here as we had two instruments
for one endogenous variable (2-1) or one overidentifying
restriction.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
